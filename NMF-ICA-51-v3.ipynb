{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: [Daehee Yang]\n",
    "# Purpose: Modularized NMF-ICA spectrum decomposition using Hyperspy\n",
    "# Source: Refactored from original workflow\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "import hyperspy.api as hs # noqa\n",
    "import numpy as np # noqa\n",
    "import matplotlib.pyplot as plt # noqa\n",
    "from sklearn.cluster import KMeans # noqa\n",
    "from sklearn.preprocessing import MinMaxScaler # noqa\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def remove_negative(signal):\n",
    "    \"\"\"Ensure spectrum has no negative values.\"\"\"\n",
    "    corrected = signal.data - np.min(signal.data)\n",
    "    new_signal = hs.signals.EELSSpectrum(corrected)\n",
    "    for i in range(3):\n",
    "        new_signal.axes_manager[i].size = signal.axes_manager[i].size\n",
    "        new_signal.axes_manager[i].scale = signal.axes_manager[i].scale\n",
    "        new_signal.axes_manager[i].offset = signal.axes_manager[i].offset\n",
    "        new_signal.axes_manager[i].units = signal.axes_manager[i].units\n",
    "    return new_signal\n",
    "\n",
    "def run_nmf(signal, n_components=4, max_iter=500000):\n",
    "    \"\"\"Run NMF decomposition on signal.\"\"\"\n",
    "    signal.decomposition(\n",
    "        normalize_poissonian_noise=True,\n",
    "        algorithm=\"NMF\",\n",
    "        output_dimension=n_components,\n",
    "        max_iter=max_iter\n",
    "    )\n",
    "\n",
    "def run_ica(signal, n_components=4, max_iter=50000):\n",
    "    \"\"\"Apply ICA to decompose sources after NMF.\"\"\"\n",
    "    signal.blind_source_separation(\n",
    "        number_of_components=n_components,\n",
    "        algorithm='sklearn_fastica',\n",
    "        diff_order=1,\n",
    "        reverse_component_criterion=\"loadings\",\n",
    "        max_iter=max_iter\n",
    "    )\n",
    "\n",
    "def segment_by_kmeans(signal, n_clusters):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering on a 2D Hyperspy signal and return:\n",
    "    - Binary segmentation mask\n",
    "    - Silhouette Coefficient\n",
    "    - Dunn Index\n",
    "\n",
    "    Parameters:\n",
    "        signal (hs.signals.Signal2D): Input signal to segment.\n",
    "        n_clusters (int): Number of clusters to form.\n",
    "\n",
    "    Returns:\n",
    "        segmented (hs.signals.Signal2D): Binary segmentation mask.\n",
    "        silhouette (float): Silhouette Coefficient.\n",
    "        dunn (float): Dunn Index.\n",
    "    \"\"\"\n",
    "    # Reshape and normalize\n",
    "    data = signal.data\n",
    "    h, w = data.shape\n",
    "    reshaped = data.reshape(-1, 1)\n",
    "    scaled = MinMaxScaler().fit_transform(reshaped)\n",
    "\n",
    "    # K-means clustering\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=0, n_init=50)\n",
    "    model.fit(scaled)\n",
    "    labels = model.labels_.reshape(h, w)\n",
    "\n",
    "    # Binary segmentation: background = lowest mean intensity cluster\n",
    "    intensities = [data[labels == i].mean() for i in range(n_clusters)]\n",
    "    background_idx = int(np.argmin(intensities))\n",
    "    binary = (labels != background_idx).astype(np.uint8) * 255\n",
    "    segmented = hs.signals.Signal2D(binary)\n",
    "    segmented.change_dtype(\"uint16\")\n",
    "\n",
    "    return segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yang\\miniconda3\\envs\\venv_py38\\lib\\site-packages\\hyperspy\\signal.py:2450: UserWarning: Setting the `metadata` attribute is deprecated and will be removed in HyperSpy 2.0. Use the `set_item` and `add_dictionary` methods of the `metadata` attribute instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Example Usage\n",
    "# =====================\n",
    "\n",
    "# Set parameters\n",
    "path = 'E:/DaeheeYang/data/2024-02-25_MEA-HM-ref-EOL-sulfur/analysis/SI data (2)'\n",
    "filename = 'EELS Spectrum Image (high-loss) (aligned) (aligned)_Cleaned'\n",
    "save_name = 'decompose'\n",
    "ext = 'dm4'\n",
    "\n",
    "crop_range = (280.0, 300.0)\n",
    "n_components = 4\n",
    "\n",
    "# Load and preprocess spectrum\n",
    "a = hs.load(f'{path}/{filename}.{ext}')\n",
    "s = a.isig[crop_range[0] : crop_range[1]]\n",
    "s = remove_negative(s)\n",
    "s.metadata = a.metadata\n",
    "#s.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposition info:\n",
      "  normalize_poissonian_noise=True\n",
      "  algorithm=NMF\n",
      "  output_dimension=4\n",
      "  centre=None\n",
      "scikit-learn estimator:\n",
      "NMF(max_iter=500000, n_components=4)\n",
      "[########################################] | 100% Completed | 117.03 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hyperspy.learn.mva:HyperSpy already performs its own data whitening (whiten_method='PCA'), so it is ignored for algorithm='sklearn_fastica'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blind source separation info:\n",
      "  number_of_components=4\n",
      "  algorithm=sklearn_fastica\n",
      "  diff_order=1\n",
      "  reverse_component_criterion=loadings\n",
      "  whiten_method=PCA\n",
      "scikit-learn estimator:\n",
      "FastICA(max_iter=50000, tol=1e-10, whiten=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yang\\miniconda3\\envs\\venv_py38\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run decomposition\n",
    "run_nmf(s, n_components)\n",
    "run_ica(s, n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fe457162bb403a9362f4afe0feb36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Decomposition component index', layout=Layout(width='15%')), IntSli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fd8fd2a26349faa017c598a21863f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='BSS component index', layout=Layout(width='15%')), IntSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#If you want to check the results, please run the code below\n",
    "s.plot_decomposition_loadings()\n",
    "s.plot_decomposition_factors()\n",
    "s.plot_decomposition_results()\n",
    "s.plot_bss_loadings()\n",
    "s.plot_bss_factors()\n",
    "s.plot_bss_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result of decomposition\n",
    "s.export_bss_results(folder=f'{path}/{save_name}',\n",
    "                    factor_format='MSA',\n",
    "                    loading_format='TIFF')\n",
    "s.export_decomposition_results(folder=f'{path}/{save_name}',\n",
    "                            factor_format='MSA',\n",
    "                            loading_format='TIFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and segment coefficient maps\n",
    "ion_data = hs.load(f\"{path}/ionomer.{ext}\")\n",
    "ionomer_seg = segment_by_kmeans(ion_data, n_clusters=4)\n",
    "ionomer_seg.plot(title='ionomer')\n",
    "\n",
    "sig_data = hs.load(f\"{path}/sigma.{ext}\")\n",
    "sigma_seg = segment_by_kmeans(sig_data, n_clusters=3)\n",
    "sigma_seg.plot(title='sigma')\n",
    "\n",
    "pi_data = hs.load(f\"{path}/pi.{ext}\")\n",
    "pi_seg = segment_by_kmeans(pi_data, n_clusters=3)\n",
    "pi_seg.plot(title='pi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and segment coefficient maps with metric output\n",
    "ion_data = hs.load(f\"{path}/ionomer.{ext}\")\n",
    "ionomer_seg, ion_sil, ion_dunn = segment_by_kmeans(ion_data, n_clusters=4)\n",
    "ionomer_seg.plot(title=f'ionomer\\nSilhouette={ion_sil:.3f}, Dunn={ion_dunn:.3f}')\n",
    "\n",
    "sig_data = hs.load(f\"{path}/sigma.{ext}\")\n",
    "sigma_seg, sig_sil, sig_dunn = segment_by_kmeans(sig_data, n_clusters=4)\n",
    "sigma_seg.plot(title=f'sigma\\nSilhouette={sig_sil:.3f}, Dunn={sig_dunn:.3f}')\n",
    "\n",
    "pi_data = hs.load(f\"{path}/pi.{ext}\")\n",
    "pi_seg, pi_sil, pi_dunn = segment_by_kmeans(pi_data, n_clusters=4)\n",
    "pi_seg.plot(title=f'pi\\nSilhouette={pi_sil:.3f}, Dunn={pi_dunn:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total area : 5026\n",
      "Ionomer + support : 3912\n",
      "Only ionomer : 293\n",
      "Only support : 821\n"
     ]
    }
   ],
   "source": [
    "# Support and total area maps\n",
    "support_area = ((pi_seg.data + sigma_seg.data) > 0).astype(np.uint8) * 255\n",
    "support_area = hs.signals.Signal2D(support_area)\n",
    "support_area.change_dtype(\"uint16\")\n",
    "\n",
    "total_area = ((ionomer_seg.data + pi_seg.data + sigma_seg.data) > 0).astype(np.uint8) * 255\n",
    "total_area = hs.signals.Signal2D(total_area)\n",
    "total_area.change_dtype(\"uint16\")\n",
    "\n",
    "# Combined area logic and statistics\n",
    "area_seg = (ionomer_seg.data * 3 + support_area.data * 2)\n",
    "area_seg = hs.signals.Signal2D(area_seg)\n",
    "\n",
    "total_count = (total_area.data == 255).sum()\n",
    "both_count = np.sum(area_seg.data == 255 * 5)\n",
    "only_ionomer = np.sum(area_seg.data == 255 * 3)\n",
    "only_support = np.sum(area_seg.data == 255 * 2)\n",
    "\n",
    "print(f\"Total area : {total_count}\")\n",
    "print(f\"Ionomer + support : {both_count}\")\n",
    "print(f\"Only ionomer : {only_ionomer}\")\n",
    "print(f\"Only support : {only_support}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save segmentation maps\n",
    "ionomer_seg.save(f\"{path}/seg_map/ionomer_seg_{(ionomer_seg.data == 255).sum()}.tif\")\n",
    "sigma_seg.save(f\"{path}/seg_map/sigma_seg_{(sigma_seg.data == 255).sum()}.tif\")\n",
    "pi_seg.save(f\"{path}/seg_map/pi_seg_{(pi_seg.data == 255).sum()}.tif\")\n",
    "support_area.save(f\"{path}/seg_map/support_map_{(support_area.data == 255).sum()}.tif\")\n",
    "total_area.save(f\"{path}/seg_map/total_map_{(total_area.data == 255).sum()}.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save statistics\n",
    "with open(f\"{path}/seg_map/Statistical_analysis.txt\", 'w') as txt:\n",
    "    txt.writelines([\n",
    "        f\"Total area : {total_count}\\n\",\n",
    "        f\"Ionomer + support : {both_count}\\n\",\n",
    "        f\"Only ionomer : {only_ionomer}\\n\",\n",
    "        f\"Only support : {only_support}\\n\"\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
