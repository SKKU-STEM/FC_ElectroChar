{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention_unet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttentionUNet \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DBSCAN\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'core'"
     ]
    }
   ],
   "source": [
    "import warnings # noqa\n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "import os, sys # noqa\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('PMA-Net-Autobinning'))))\n",
    "import torch # noqa\n",
    "import hyperspy.api as hs # noqa\n",
    "import numpy as np # noqa\n",
    "from tqdm import tqdm # noqa\n",
    "from core.attention_unet import AttentionUNet # noqa\n",
    "from sklearn.cluster import DBSCAN # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model_dir = \"../model/240920_model-haadf.pt\"\n",
    "    net = AttentionUNet(img_ch = 1, output_ch = 3)\n",
    "    net.load_state_dict(torch.load(model_dir))\n",
    "    return net\n",
    "\n",
    "def run_model(input_data_dir, model, device, cal_dist):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        input_sig = hs.load(input_data_dir)\n",
    "        scale = input_sig.axes_manager[0].scale\n",
    "        input_data = (input_sig - input_sig.data.mean()) / input_sig.data.std()\n",
    "        input_data = torch.from_numpy(input_data.data.copy())\n",
    "        input_data = input_data.view(-1, 1, input_data.shape[0], input_data.shape[1])\n",
    "        input_data = input_data.to(device).float()\n",
    "        output = model(input_data)\n",
    "        output = torch.argmax(output, dim = 1)\n",
    "        output = output.cpu().detach().numpy()[0]\n",
    "        output = hs.signals.Signal2D(output)\n",
    "        cluster_input = np.array(np.where(output.data > 0)).T\n",
    "        cluster_model = DBSCAN(eps = 2, min_samples = 12)\n",
    "        cluster_model.fit(cluster_input)\n",
    "        instance_seg_map = np.zeros((input_sig.data.shape[0], input_sig.data.shape[1]))\n",
    "        instance_seg_map[np.where(output.data > 0)] = cluster_model.labels_ + 1\n",
    "        instance_seg_map = hs.signals.Signal2D(instance_seg_map)\n",
    "        label_max = int(instance_seg_map.data.max() + 1)\n",
    "\n",
    "        seg_map = np.zeros((input_sig.data.shape[0], input_sig.data.shape[1]))\n",
    "\n",
    "        for i in range(1, label_max):\n",
    "            label1 = (output.data[instance_seg_map.data == i] == 1).sum()\n",
    "            label2 = (output.data[instance_seg_map.data == i] == 2).sum()\n",
    "            if label1 > label2:\n",
    "                seg_map[instance_seg_map.data == i] = 1\n",
    "            else:\n",
    "                seg_map[instance_seg_map.data == i] = 2\n",
    "\n",
    "        seg_map = hs.signals.Signal2D(seg_map)\n",
    "        seg_map.change_dtype(\"uint8\")\n",
    "\n",
    "        single_area = []\n",
    "        agg_area = []\n",
    "        single_distance = []\n",
    "        agg_distance = []\n",
    "\n",
    "        for i in range(1, label_max):\n",
    "            area = (instance_seg_map.data == i)\n",
    "            if np.unique(seg_map.data[np.where(area)]).item() == 1:\n",
    "                single_area.append(area.sum() * scale * scale)\n",
    "                current_label = 1\n",
    "            elif np.unique(seg_map.data[np.where(area)]).item() == 2:\n",
    "                agg_area.append(area.sum() * scale * scale)\n",
    "                current_label = 2\n",
    "            if cal_dist:\n",
    "                cluster0 = np.array(np.where(area)).T\n",
    "                for dist_i in range(i + 1, label_max):\n",
    "                    cluster1 = np.where(instance_seg_map.data == dist_i)\n",
    "                    if np.unique(seg_map.data[cluster1]).item() == current_label:\n",
    "                        distance_min = 99999999999\n",
    "                        cluster1 = np.array(cluster1).T\n",
    "                        for pixel_i in range(len(cluster1)):\n",
    "                            min_dist = ((cluster0 - cluster1[pixel_i])**2).sum(axis = 1).min()\n",
    "                            if distance_min > min_dist:\n",
    "                                distance_min = min_dist\n",
    "                        if current_label == 1:\n",
    "                            single_distance.append(np.sqrt(distance_min).item() * scale)\n",
    "                        elif current_label == 2:\n",
    "                            agg_distance.append(np.sqrt(distance_min).item() * scale)\n",
    "\n",
    "\n",
    "        single_area = np.array(single_area)\n",
    "        agg_area = np.array(agg_area)\n",
    "        single_distance = np.array(single_distance)\n",
    "        agg_distance = np.array(agg_distance)\n",
    "        \n",
    "        return seg_map, single_area, agg_area, single_distance, agg_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [02:44<00:00, 14.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# Parameter setting\n",
    "path = 'E:/'\n",
    "folder_name = ''\n",
    "dataset_dir = f'{path}/{folder_name}'\n",
    "result_dir = f'{path}/{folder_name}_result-model_haadf'\n",
    "cal_dist = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = load_model()\n",
    "model.to(device)\n",
    "dataset_list = os.listdir(dataset_dir)\n",
    "for data_dir in tqdm(dataset_list):\n",
    "    if (data_dir[-4:] == \".dm4\")|(data_dir[-4:] == \".dm3\")|(data_dir[-4:] == \".tif\"):\n",
    "        input_data_dir = f\"{dataset_dir}/{data_dir}\"\n",
    "        seg_map, single_area, agg_area, single_distance, agg_distance = run_model(input_data_dir = input_data_dir,\n",
    "                                                                                model = model,\n",
    "                                                                                device = device,\n",
    "                                                                                cal_dist = cal_dist)\n",
    "        seg_map.save(f\"{result_dir}/{data_dir[:-4]}.tif\")\n",
    "        np.savetxt(f\"{result_dir}/{data_dir[:-4]}_single_area.csv\", single_area, delimiter = ',')\n",
    "        np.savetxt(f\"{result_dir}/{data_dir[:-4]}_agg_area.csv\", agg_area, delimiter = ',')\n",
    "        if cal_dist:\n",
    "            np.savetxt(f\"{result_dir}/{data_dir[:-4]}_single_dist.csv\", single_distance, delimiter = ',')\n",
    "            np.savetxt(f\"{result_dir}/{data_dir[:-4]}_agg_dist.csv\", agg_distance, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
